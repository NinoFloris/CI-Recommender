{
 "metadata": {
  "name": "nb"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Group #2 - Project"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "First Assignment"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Recommender"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "In this part, we'll see how have we build the recommender."
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Distance function"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "jQuery20209501825489569455_1386608968613?",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "Second Assignment"
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": "Clustering Algorithm"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "This algorithm show how do we've adapt the k-means clustering algorithm to our documents.\nFirst, this function takes as parameters :"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def cluster(numOfClusters, set, distFunction):\n    ",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "The set is the set from which we'll do some clusters, based on a distance function.\nIt also needs to know how much clusters do we want at the end.\n\nWe can see beneath how the initialization part is implemented :"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "centroids = createFirstCentroids(set, numOfClusters)\nclusterArray = []\nnumberOfChanges = 10\nnumberOfRounds = 0",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "centroids will contain the centroids points. Those points are elements of the set. createFirstCentroids choose randomly an element from the set and put it back in an array and do this as much as the number of clusters we want (numOfCluster).\nclusterArray will be an array as big as \"set\", for each element, its cluster id is stored in this array.\nnumberOfChanges & numberOfRounds are here to stop the algorithm when it will has converged, or when we'll be bored (see the while condition beneath)."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "while(numberOfChanges>2 and numberOfRounds<150):",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "Then, for each element from the set, we'll try to find its closer cluster, using the distance function.\nWhen this is done, the algorithm call a function to designate the next centroid for each cluster.\nThis function prototype  is :"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def updatecentroids(set, clusterArray, distFunction, numOfClusters):",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "It needs the clusterArray to know the elements of one cluster.\nThen the set and the distance function are here to help us in finding the next centroid for each cluster.\nThe number of cluster is here to make the algorithm more easy to implement, we could have used clusterArray to get back the number of cluster, but it is more readable like this."
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": "Third Assignment"
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": "TF IDF"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "In this part, we'll see how we implement the Term Frequency - Inverse Document Frequency (TF-IDF)"
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "The TF here function measures the frequency of words in documents relative to the most common term."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#adaptive TF = every word with its normalized value for max term, e.g. TFid = (fid / maxk fkd)\n#tfrequency of word i in document d is that divided by the frequency of word k where k is the most common term in d\ndef TF(wordlist):\n    #count all occurences of words and sort from most common to least, return list[(word,count),]\n    tfrequency = collections.Counter(wordlist).most_common()\n    #get the count of the most common term for this document, get first elements' count\n    tmax = tfrequency[0][1]\n    #return TF score per word based on the frequency of every word in tfrequency divided by tmax\n    return [(f[0], float(f[1])/tmax) for f in tfrequency]",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "The main TFIDF function here builds the dictionary of documents with their term frequency by calling the TF function."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def TFIDF(documents):\n    tfdict = {}    \n    dfdict = collections.defaultdict(int)\n    for pmid, document in documents.iteritems():\n        words = document.split()\n        #skip on lower than 5 words, no data is provided or it is useless as tf-idf material\n        if(len(words) < 5):\n            continue\n\n        tfdict[pmid] = TF(words)\n        #combining this loop for some df as well\n        for word in set(words):\n            dfdict[word] += 1\n\n    tfidfdict = {}\n    idfdict = idf(dfdict,len(documents))\n    for pmid, tf in tfdict.iteritems():\n        tfidfdict[pmid] = {term: (count * idfdict[term]) for term, count in tf}\n\n    return tfidfdict",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "raw",
     "metadata": {},
     "source": "The idf function inverts the term frequencies so that frequencies are scored by uniqueness."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def idf(dftermsdict, documentN):\n    idfdict = {}\n    for term, df in dftermsdict.iteritems():\n        idfdict[term] = math.log(documentN/df, 2)\n\n    return idfdict",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
